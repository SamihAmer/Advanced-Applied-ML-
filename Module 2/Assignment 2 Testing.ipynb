{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 2.7.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 72\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/samihamer/Desktop/Advanced Applied AI Summer 2025/Module 2/MNIST/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import struct\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "        with open(images_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "            images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 28, 28, 1)\n",
    "            images = ((images / 255.) - .5) * 2\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 60000, HxW= 28x28\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr = load_mnist(DATA_DIR, kind='train')\n",
    "print(f'N= {X_tr.shape[0]}, HxW= {X_tr.shape[1]}x{X_tr.shape[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 60000, HxW= 28x28\n",
      "N= 10000, HxW= 28x28\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr = load_mnist(DATA_DIR, kind='train')\n",
    "print(f'N= {X_tr.shape[0]}, HxW= {X_tr.shape[1]}x{X_tr.shape[2]}')\n",
    "\n",
    "X_ts, y_ts = load_mnist(DATA_DIR, kind='t10k')\n",
    "print(f'N= {X_ts.shape[0]}, HxW= {X_ts.shape[1]}x{X_ts.shape[2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to work with Conv2D - Batch, Chn, H, W\n",
    "X_tr = X_tr.reshape(X_tr.shape[0], 1, X_tr.shape[1], X_tr.shape[2])\n",
    "X_ts = X_ts.reshape(X_ts.shape[0], 1, X_ts.shape[1], X_ts.shape[2])\n",
    "\n",
    "IMG_CHANNEL= 1  # color channel\n",
    "MLP_HIDDEN= 64  # Hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchMLP(nn.Module):\n",
    "    def __init__(self, epochs=10, eta=0.001, minibatch_size=5000, seed=0):\n",
    "        super().__init__()\n",
    "        self.random = np.random.RandomState(seed)  # shuffle mini batches\n",
    "        self.epochs = epochs  # number of iterations\n",
    "        self.eta = eta  # learning rate\n",
    "        self.minibatch_size = minibatch_size  # size of training batch - 1 would not work\n",
    "        self.optimizer = None\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.model = None\n",
    "\n",
    "    def init_layers(self, _M:int, _K:int) -> None:\n",
    "        # data structure\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(IMG_CHANNEL, MLP_HIDDEN, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(MLP_HIDDEN),\n",
    "\n",
    "            nn.Conv2d(MLP_HIDDEN, MLP_HIDDEN*2, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(start_dim=1),\n",
    "\n",
    "            # 4*4 is computed in the above cell\n",
    "            nn.Linear(MLP_HIDDEN*2 * 4*4, 1024),  # 1024 arbitrary\n",
    "            nn.BatchNorm1d(1024),\n",
    "\n",
    "            nn.Linear(1024, _K),\n",
    "        ).to(device)\n",
    "\n",
    "    def predict(self, _X):\n",
    "        _X = torch.FloatTensor(_X).to(device, non_blocking=True)\n",
    "        assert self.model is not None\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(_X)\n",
    "        self.model.train()\n",
    "        # probs = nn.functional.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return preds.cpu().numpy()\n",
    "\n",
    "    def predict_proba(self, _X):\n",
    "        _X = torch.FloatTensor(_X).to(device, non_blocking=True)\n",
    "        assert self.model is not None\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(_X)\n",
    "        self.model.train()\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        return probs.cpu().numpy()\n",
    "\n",
    "    def fit(self, _X_train, _y_train, info=False):\n",
    "        import sys\n",
    "        n_features= _X_train.shape[1]\n",
    "        n_output= np.unique(_y_train).shape[0]  # number of class labels\n",
    "\n",
    "        _X_train = torch.FloatTensor(_X_train).to(device, non_blocking=True)\n",
    "        _y_train = torch.LongTensor(_y_train).to(device, non_blocking=True).long()\n",
    "\n",
    "        self.init_layers(n_features, n_output)\n",
    "        self.optimizer = torch.optim.Rprop(self.model.parameters(), lr=self.eta)  # connect model to optimizer\n",
    "\n",
    "        for e in range(self.epochs):\n",
    "            indices = np.arange(_X_train.shape[0])\n",
    "            self.random.shuffle(indices)  # shuffle the data each epoch\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                net_out = self.model(_X_train[batch_idx])\n",
    "\n",
    "                loss = self.loss_func(net_out, _y_train[batch_idx])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if info:\n",
    "                    sys.stderr.write(f\"\\r{e+1:03d} Loss: {loss.item():6.5f}\")\n",
    "                    sys.stderr.flush()\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "013 Loss: 0.01740"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.991\n",
      "CPU times: user 15min 55s, sys: 7min 14s, total: 23min 10s\n",
      "Wall time: 15min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlp = PyTorchMLP(epochs=13).to(device)\n",
    "mlp.fit(X_tr, y_tr, info=True)\n",
    "\n",
    "# Testing dataset\n",
    "y_pred = mlp.predict(X_ts)\n",
    "\n",
    "print(f'Accuracy= {np.sum(y_pred==y_ts)/len(X_ts):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9299abf7b6d9495f9d2f4dae24d4b789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m example \u001b[38;5;241m=\u001b[39m X_ts[example_idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get explanation\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m explanation \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain_instance(\n\u001b[1;32m     35\u001b[0m     example,\n\u001b[1;32m     36\u001b[0m     predict_fn,\n\u001b[1;32m     37\u001b[0m     segmentation_fn\u001b[38;5;241m=\u001b[39msegmenter,\n\u001b[1;32m     38\u001b[0m     top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     39\u001b[0m     hide_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Plot original image and explanation\u001b[39;00m\n\u001b[1;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, digit \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lime/lime_image.py:216\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    212\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mtop_labels\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m top:\n\u001b[1;32m    214\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[1;32m    215\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[0;32m--> 216\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore, ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mexplain_instance_with_data(\n\u001b[1;32m    217\u001b[0m         data, labels, distances, label, num_features,\n\u001b[1;32m    218\u001b[0m         model_regressor\u001b[38;5;241m=\u001b[39mmodel_regressor,\n\u001b[1;32m    219\u001b[0m         feature_selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret_exp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lime/lime_base.py:182\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Takes perturbed data, labels and distances, returns explanation.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    local_pred is the prediction of the explanation model on the original instance\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_fn(distances)\n\u001b[0;32m--> 182\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m neighborhood_labels[:, label]\n\u001b[1;32m    183\u001b[0m used_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection(neighborhood_data,\n\u001b[1;32m    184\u001b[0m                                        labels_column,\n\u001b[1;32m    185\u001b[0m                                        weights,\n\u001b[1;32m    186\u001b[0m                                        num_features,\n\u001b[1;32m    187\u001b[0m                                        feature_selection)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create LIME explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# Define segmentation algorithm\n",
    "segmenter = SegmentationAlgorithm('quickshift', kernel_size=4, max_dist=200, ratio=0.2)\n",
    "\n",
    "# Function to preprocess images for LIME\n",
    "def preprocess_for_lime(images):\n",
    "    return images.reshape(-1, 28, 28)\n",
    "\n",
    "# Function to get model predictions for LIME\n",
    "def predict_fn(images):\n",
    "    # Reshape images to match model input\n",
    "    images = images.reshape(-1, 1, 28, 28)\n",
    "    # Get probabilities for all classes\n",
    "    probs = mlp.predict_proba(images)\n",
    "    # Return probabilities for the predicted class only\n",
    "    return probs[:, np.argmax(probs[0])]\n",
    "\n",
    "# Get explanations for each digit class\n",
    "plt.figure(figsize=(15, 10))\n",
    "for digit in range(10):\n",
    "    # Find an example of the current digit\n",
    "    digit_indices = np.where(y_ts == digit)[0]\n",
    "    if len(digit_indices) > 0:\n",
    "        example_idx = digit_indices[0]\n",
    "        example = X_ts[example_idx].reshape(28, 28)\n",
    "        \n",
    "        # Get explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            example,\n",
    "            predict_fn,\n",
    "            segmentation_fn=segmenter,\n",
    "            top_labels=1,\n",
    "            hide_color=0,\n",
    "            num_samples=1000\n",
    "        )\n",
    "        \n",
    "        # Plot original image and explanation\n",
    "        plt.subplot(2, 5, digit + 1)\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0],\n",
    "            positive_only=True,\n",
    "            num_features=5,\n",
    "            hide_rest=True\n",
    "        )\n",
    "        plt.imshow(mask, cmap='RdBu', alpha=0.7)\n",
    "        plt.imshow(example, cmap='gray', alpha=0.5)\n",
    "        plt.title(f'Digit {digit}')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
